{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqqtVm4h8Sy1C7IXVTrdHI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amutharun/GenAIWorkshop/blob/main/Quick_Start_Guide.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quick Start Guide to Set up an environment variable file\n",
        "\n",
        "**Instructions for using Azure Open AI models**\n",
        "\n",
        "*  Open Notepad or Notepad++\n",
        "*  Paste the below contents\n",
        "\n",
        "```\n",
        "AZURE_OPENAI_API_KEY = \"...\"\n",
        "AZURE_API_TYPE = \"azure\"\n",
        "AZURE_OPENAI_ENDPOINT = \"...\"\n",
        "AZURE_API_VERSION = \"...\"\n",
        "```\n",
        "\n",
        "* Save the file with a file name \".env\" with file type as \"All Files\"\n",
        "\n",
        "* Drag and drop/ Upload the .env file in the Files section on the sidebar"
      ],
      "metadata": {
        "id": "38C1WTuHUAQ3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyNuok9MK2ZO",
        "outputId": "248c8de8-0108-4b84-e6c8-52cb2cdbea6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-zc_kI5O7dz",
        "outputId": "6b2ed451-2331-495b-9842-c1b281d522fa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if we are using the direct openai way\n",
        "\n",
        "import os\n",
        "import openai\n",
        "openai.api_type = \"azure\"\n",
        "openai.api_version = os.getenv(\"AZURE_API_VERSION\"),\n",
        "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")  # Your Azure OpenAI resource's endpoint value.\n",
        "openai.api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n"
      ],
      "metadata": {
        "id": "prpMvSPoTUUB"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try invoking chatgpt model via API"
      ],
      "metadata": {
        "id": "WWKgspoEXYEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.chat.completions.create(\n",
        "  model=\"EAGPT35\", #this is the name of the deployed model on Azure\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Write a joke about Data Scientists\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0.5,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10klQ9h_Vq35",
        "outputId": "2fdee62d-7536-44fc-cc5f-30ae690661e1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why did the data scientist bring a ladder to work?\n",
            "\n",
            "Because they wanted to reach new heights in data analysis!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try GPT 4 Turbo model (costlier variant with longer context window by changing the model name (deployed model name on Azure Open AI)"
      ],
      "metadata": {
        "id": "3Yro4PrAXcTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.chat.completions.create(\n",
        "  model=\"EAGPT4\", #this is the name of the deployed model on Azure\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Write a joke about Data Scientists\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0.5,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpIy0BWNXvBk",
        "outputId": "df51d2d9-e1b2-42a0-fc0b-ea8fec96a977"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why don't data scientists ever play hide and seek?\n",
            "\n",
            "Because good luck hiding when they can track your location, predict your next move, and estimate the probability of you hiding in a specific spot!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets try accessing Open AI models deployed on Azure Open AI using Langchain"
      ],
      "metadata": {
        "id": "L9CfVkSeWatX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IDUQkoF1XkrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "id": "366ivvCRWZP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import HumanMessage\n",
        "from langchain_community.chat_models import AzureChatOpenAI"
      ],
      "metadata": {
        "id": "CdwuP_tJLzaQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.chat_models import AzureChatOpenAI"
      ],
      "metadata": {
        "id": "0mlKt9VSK_Kx"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AzureChatOpenAI(\n",
        "    openai_api_version=os.getenv(\"AZURE_API_VERSION\"),\n",
        "    azure_deployment=\"EAGPT35\",\n",
        ")"
      ],
      "metadata": {
        "id": "qgnKbZdVMX5m"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message = HumanMessage(\n",
        "    content=\"Write a joke about Data scientists\"\n",
        ")\n",
        "model([message])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiQxLnGNNdcS",
        "outputId": "82ec5732-196e-4c0e-aa59-36aeda8922bf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Why did the data scientist bring a ladder to the office?\\n\\nBecause they wanted to climb the data hierarchy and reach new heights in analytics!')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's find out the cost consumed by each model using callbacks"
      ],
      "metadata": {
        "id": "7y2JwSdQRLlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.callbacks import get_openai_callback"
      ],
      "metadata": {
        "id": "EzlF3J3XQa4x"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AzureChatOpenAI(\n",
        "   openai_api_version=os.getenv(\"AZURE_API_VERSION\"),\n",
        "    azure_deployment=\"EAGPT35\",\n",
        "   temperature =0\n",
        ")\n",
        "with get_openai_callback() as cb:\n",
        "    print(model([message]))\n",
        "    print(cb)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tc-5godEQyFd",
        "outputId": "dfc248f9-1d78-4c97-d4e0-002b961bc41a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='Why did the data scientist bring a ladder to work?\\n\\nBecause they wanted to climb the data hierarchy!'\n",
            "Tokens Used: 33\n",
            "\tPrompt Tokens: 13\n",
            "\tCompletion Tokens: 20\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.000119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AzureChatOpenAI(\n",
        "   openai_api_version=os.getenv(\"AZURE_API_VERSION\"),\n",
        "    azure_deployment=\"EAGPT4\",temperature=0\n",
        ")\n",
        "with get_openai_callback() as cb:\n",
        "    print(model([message]))\n",
        "    print(cb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DUexg8MQZM_",
        "outputId": "97931ad1-143a-4b94-bac1-e45805cc7730"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content=\"Why don't data scientists ever play hide and seek?\\n\\nBecause good luck hiding when they can track your every move!\"\n",
            "Tokens Used: 36\n",
            "\tPrompt Tokens: 13\n",
            "\tCompletion Tokens: 23\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.0017699999999999999\n"
          ]
        }
      ]
    }
  ]
}